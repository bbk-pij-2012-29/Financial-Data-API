{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_companies = pd.read_csv('data/us-companies.csv', sep=';')\n",
    "df_us_companies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industries = pd.read_csv('data/industries.csv', sep=';')\n",
    "df_industries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_shareprices_daily = pd.read_csv('data/us-shareprices-daily.csv', sep=';')\n",
    "df_us_shareprices_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_balance_ttm = pd.read_csv('data/us-balance-ttm.csv', sep=';')\n",
    "df_us_balance_ttm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_balance_ttm[df_us_balance_ttm.Ticker == 'WFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_balance_ttm.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_balance_ttm['Currency'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_balance_ttm[df_us_balance_ttm['Ticker'] == 'IBM'].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_balance_ttm[df_us_balance_ttm['Ticker'] == 'LVGO'].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_balance_ttm.Currency.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_balance_ttm.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Dev ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialDataAPI:\n",
    "    __data_dict = None\n",
    "    __field_meta = None\n",
    "    __date_format = '%Y-%m-%d'\n",
    "    \n",
    "    def __init__(self, source='./data', sep=';'):\n",
    "        if FinancialDataAPI.__data_dict is None:\n",
    "            # Load all raw data sets\n",
    "            files = [f for f in os.listdir('./data') if f[0] != '.']\n",
    "            FinancialDataAPI.__data_dict = {f.replace('.csv', '').replace('us-', ''): pd.read_csv('{}/{}'.format(source, f), sep=sep) for f in files}\n",
    "\n",
    "            # Convert the date columns into the datetime64 type\n",
    "            for data_set in FinancialDataAPI.__data_dict:\n",
    "                df = FinancialDataAPI.__data_dict[data_set]\n",
    "                for col in list(df.columns):\n",
    "                    if 'date' in col.lower():\n",
    "                        df[col] = df[col].astype('datetime64[ns]')\n",
    "                    \n",
    "        \n",
    "        if FinancialDataAPI.__field_meta is None:\n",
    "            # load fields metadata\n",
    "            FinancialDataAPI.__field_meta = pd.read_csv('./meta/fields-meta.csv').fillna('')\n",
    "    \n",
    "    \n",
    "    def reload_data_sets_and_meta(self, source='./data', sep=';'):\n",
    "        \"\"\"\n",
    "            The function reloads the raw data sets and data meta from the drive.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Load all raw data sets\n",
    "        files = [f for f in os.listdir('./data') if f[0] != '.']\n",
    "        FinancialDataAPI.__data_dict = {f.replace('.csv', '').replace('us-', ''): pd.read_csv('{}/{}'.format(source, f), sep=sep) for f in files}\n",
    "\n",
    "        # Convert the date columns into the datetime64 type\n",
    "        for data_set in FinancialDataAPI.__data_dict:\n",
    "            df = FinancialDataAPI.__data_dict[data_set]\n",
    "            for col in list(df.columns):\n",
    "                if 'date' in col.lower():\n",
    "                    df[col] = df[col].astype('datetime64[ns]')\n",
    "        \n",
    "        # load fields metadata\n",
    "        FinancialDataAPI.__field_meta = pd.read_csv('./meta/fields-meta.csv').fillna('')\n",
    "    \n",
    "    \n",
    "    def list_fields(self):\n",
    "        \"\"\"\n",
    "            The function shows the full list of fields\n",
    "        \"\"\"\n",
    "        \n",
    "        df = FinancialDataAPI.__field_meta[['Long Name', 'Short Name', 'func', 'doc']].copy()\n",
    "        df['func'] = df['func'].str[4:]\n",
    "        df = df.rename(columns={'func': 'Category', 'doc': 'Quick Document'})\n",
    "        \n",
    "        return df.copy()\n",
    "    \n",
    "    \n",
    "    def list_data_category(self):\n",
    "        \"\"\"\n",
    "            The function lists all the data categories available\n",
    "        \"\"\"\n",
    "        \n",
    "        return [cat.replace('get_', '') for cat in FinancialDataAPI.__field_meta['func'].unique().tolist()]\n",
    "        \n",
    "    \n",
    "    def list_fields_by_category(self, category_list):\n",
    "        \"\"\"\n",
    "            The function returns a list of fields for a given category list\n",
    "            category_list: list of categories\n",
    "        \"\"\"\n",
    "        \n",
    "        category_list = [f'get_{cat}' for cat in category_list]\n",
    "        df = FinancialDataAPI.__field_meta[FinancialDataAPI.__field_meta['func'].isin(category_list)]\n",
    "        df = df[['Long Name', 'Short Name', 'func', 'doc']]\n",
    "        df['func'] = df['func'].str[4:]\n",
    "        df = df.rename(columns={'func': 'Category', 'doc': 'Quick Document'})\n",
    "        \n",
    "        return df.copy()\n",
    "    \n",
    "    \n",
    "    def list_data_sets(self):\n",
    "        \"\"\"\n",
    "            The function retuns a list of names of the raw data sets.\n",
    "        \"\"\"\n",
    "        \n",
    "        return list(FinancialDataAPI.__data_dict.keys())\n",
    "    \n",
    "    \n",
    "    def get_data_set(self, data_set):\n",
    "        \"\"\"\n",
    "            The function returns raw data set for a given name of the data set.\n",
    "        \"\"\"\n",
    "        \n",
    "        return FinancialDataAPI.__data_dict[data_set]\n",
    "    \n",
    "    \n",
    "    def get_classification(self, level='Sector'):\n",
    "        \"\"\"\n",
    "            level: Sector (level 1), Industry (level 2)\n",
    "        \"\"\"\n",
    "        \n",
    "        df = FinancialDataAPI.__data_dict['industries']\n",
    "        level = level.title().strip()\n",
    "        return df[level].unique().tolist()\n",
    "    \n",
    "    \n",
    "    def get_all_tickers(self, as_of_date=date.today()):\n",
    "        \"\"\"\n",
    "            The function returns a list of tickers for a given as of date.\n",
    "            The list only contains the valid tickers.\n",
    "            i.e. the tickers must have valid price on or before the as of date.\n",
    "        \"\"\"\n",
    "        \n",
    "        num_days_check = 5 # number of days to validate if we consider the stock was active\n",
    "        \n",
    "        px_df = FinancialDataAPI.__data_dict['shareprices-daily']\n",
    "        \n",
    "        # check if price exist\n",
    "        tickers_valid = px_df[\n",
    "            (px_df['Date'] <= as_of_date.strftime(FinancialDataAPI.__date_format))\n",
    "            & (px_df['Date'] >= (as_of_date - timedelta(days=num_days_check)).strftime(FinancialDataAPI.__date_format))\n",
    "        ]['Ticker'].unique().tolist()\n",
    "        \n",
    "        return tickers_valid\n",
    "    \n",
    "    \n",
    "    def get_ticker_by_classification(self, in_, level='Sector', as_of_date=date.today()):\n",
    "        \"\"\"\n",
    "            in_: List of sectors or industries\n",
    "            level: Sector (level 1), Industry (level 2)\n",
    "            as_of_date: datetime.date\n",
    "        \"\"\"\n",
    "        \n",
    "        num_days_check = 5 # number of days to validate if we consider the stock was active\n",
    "        \n",
    "        company_df = FinancialDataAPI.__data_dict['companies']\n",
    "        industry_df = FinancialDataAPI.__data_dict['industries']\n",
    "        px_df = FinancialDataAPI.__data_dict['shareprices-daily']\n",
    "        \n",
    "        level = level.title().strip()\n",
    "        industry_ids = industry_df[industry_df[level].isin(in_)]['IndustryId'].unique().tolist()\n",
    "        \n",
    "        tickers = company_df[company_df['IndustryId'].isin(industry_ids)]['Ticker'].unique().tolist()\n",
    "        \n",
    "        # check if price exist\n",
    "        tickers_valid = px_df[\n",
    "            (px_df['Ticker'].isin(tickers)) \n",
    "            & (px_df['Date'] <= as_of_date.strftime(FinancialDataAPI.__date_format))\n",
    "            & (px_df['Date'] >= (as_of_date - timedelta(days=num_days_check)).strftime(FinancialDataAPI.__date_format))\n",
    "        ]['Ticker'].unique().tolist()\n",
    "        \n",
    "        return tickers_valid\n",
    "    \n",
    "    \n",
    "    def __get_field_info(self, keyword):\n",
    "        \"\"\"\n",
    "            The function searches the field metat data given the keyword. \n",
    "            The keyword is used to match with the long and short name in lowercase.\n",
    "            The return is a dataframe contains all metadata related to the fields matched.\n",
    "        \"\"\"\n",
    "        \n",
    "        field_meta_df = FinancialDataAPI.__field_meta\n",
    "        search_long_name = field_meta_df['Long Name'].str.lower().str.contains(keyword.strip().lower())\n",
    "        search_short_name = field_meta_df['Short Name'].str.lower().str.contains(keyword.strip().lower())\n",
    "        match_df = field_meta_df[search_long_name | search_short_name]\n",
    "        match_df = match_df.reset_index().copy()\n",
    "        \n",
    "        del match_df['index']\n",
    "        \n",
    "        return match_df\n",
    "    \n",
    "    \n",
    "    def display_field_info(self, keyword):\n",
    "        \"\"\"\n",
    "            Search by field long and short names and display anyone contains the keyword.\n",
    "            keyword: str\n",
    "        \"\"\"\n",
    "        \n",
    "        match_df = self.__get_field_info(keyword)\n",
    "        \n",
    "        for i in range(len(match_df)):\n",
    "            row = match_df.iloc[i]\n",
    "            print(\"{long_name} ({short_name}) \\n  Parameters: {params} \\n  {doc} \\n\\n\".format(\n",
    "                long_name=row['Long Name'], short_name=row['Short Name'], \n",
    "                params=row['params'], doc=row['doc']\n",
    "            ))\n",
    "            \n",
    "    \n",
    "    def __get_field(self, field):\n",
    "        \"\"\"\n",
    "            The function retunrs the field metadata as dictionary for the given field name.\n",
    "            The name can either be long or short name. Not case sensitive.\n",
    "        \"\"\"\n",
    "        \n",
    "        field_meta_df = FinancialDataAPI.__field_meta\n",
    "        search_long_name = field_meta_df['Long Name'].str.lower() == field.strip().lower()\n",
    "        search_short_name = field_meta_df['Short Name'].str.lower() == field.strip().lower()\n",
    "        match_df = field_meta_df[search_long_name | search_short_name]\n",
    "        \n",
    "        if len(match_df) == 1:\n",
    "            return match_df.iloc[0].to_dict()\n",
    "        else:\n",
    "            raise Exception('Err: Could not find exact matching field.')\n",
    "    \n",
    "    \n",
    "    def __get_param_value(self, param_name, default_value=None, **kwargs):\n",
    "        \"\"\"\n",
    "            The function gets the param value from the input for the given param_name -> String\n",
    "            If the param is in the input, the input value is returned\n",
    "            If the param is not in the input, the default value is returned\n",
    "            If no default value i.e. the param is a required input, the error will be raised\n",
    "        \"\"\"\n",
    "        \n",
    "        param_list = list(kwargs.keys())\n",
    "        \n",
    "        param = [p for p in param_list if p.lower().strip() == param_name.lower().strip()]\n",
    "        \n",
    "        value = default_value\n",
    "        \n",
    "        if len(param):\n",
    "            # always take the first found param\n",
    "            param_name = param[0]\n",
    "            value = kwargs[param_name]\n",
    "        else:\n",
    "            if default_value == None:\n",
    "                raise Exception('Err: {}= is a required parameter'.format(param_name))\n",
    "        \n",
    "        # check if the value is string and if yes, make it lower case\n",
    "        if isinstance(value, str):\n",
    "            value = value.lower()\n",
    "            \n",
    "        # check if the value is Date for Datetime and if yes, make it yyyy-mm-dd string\n",
    "        dt_format = FinancialDataAPI.__date_format\n",
    "        \n",
    "        if isinstance(value, date) or isinstance(value, datetime):\n",
    "            value = value.strftime(dt_format)\n",
    "            \n",
    "        return value\n",
    "    \n",
    "    \n",
    "    def __get_description_data(self, tickers, field_dict, **kwargs):\n",
    "        \"\"\"\n",
    "            The function retrieves the description data \n",
    "            for a given list of tickers and a field metadata as dictionary (use __get_field).\n",
    "            Only one field is allowed and field must be description data.\n",
    "        \"\"\"\n",
    "        \n",
    "        field_long_name = field_dict['Long Name']\n",
    "        data_set = field_dict['data_set'].split(',')\n",
    "        join_key = field_dict['join_key'].split(',')\n",
    "        \n",
    "        df = FinancialDataAPI.__data_dict[data_set[0]]\n",
    "        \n",
    "        if len(data_set) > 1:\n",
    "            for i in range(1, len(data_set)):\n",
    "                df = pd.merge(df, FinancialDataAPI.__data_dict[data_set[i]], how='left', on=join_key[i-1], suffixes=('', '_r'))\n",
    "        \n",
    "        df = df[df['Ticker'].isin(tickers)][['Ticker', field_long_name]].copy()\n",
    "        df = df.set_index('Ticker')\n",
    "        df = df.loc[tickers]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def __expand_to_calendar_dates(self, df, tickers, start, end):\n",
    "        \"\"\"\n",
    "            The function works with pricing and market data fucntion.\n",
    "            It expands to the calendar date series from the original datafrme.\n",
    "        \"\"\"\n",
    "        \n",
    "        cols = df.columns.tolist()\n",
    "        \n",
    "        num_ticker = len(tickers)\n",
    "        dates_array = pd.date_range(start=start, end=end).values\n",
    "        num_dates = len(dates_array)\n",
    "        \n",
    "        ticker_index = np.sort(np.resize(tickers, num_dates * num_ticker))\n",
    "        dates_index = np.resize(dates_array, num_dates * num_ticker)\n",
    "        \n",
    "        expand_df = pd.DataFrame(index=[ticker_index, dates_index])\n",
    "        df = pd.concat([expand_df, df.set_index(['Ticker', 'Date'])], axis=1).reset_index()\n",
    "        \n",
    "        df.columns = cols\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def __get_pricing_data(self, tickers, field_dict, **kwargs):\n",
    "        \"\"\"\n",
    "            The function retrieves the pricing data\n",
    "            for a given list of tickers and a field metadata as dictionary (use __get_field).\n",
    "            Only one field is allowed and field must be description data.\n",
    "            \n",
    "            Param:\n",
    "            start -> Date = required\n",
    "            end -> Date = required\n",
    "            adj -> String [y/n] = y\n",
    "            fill_prev -> String [y/n]\n",
    "        \"\"\"\n",
    "        \n",
    "        data_set = field_dict['data_set']\n",
    "        field_long_name = field_dict['Long Name']\n",
    "        \n",
    "        df = FinancialDataAPI.__data_dict[data_set]\n",
    "        \n",
    "        start = self.__get_param_value('start', **kwargs)\n",
    "        end = self.__get_param_value('end', **kwargs)\n",
    "        adj = self.__get_param_value('adj', 'y', **kwargs)\n",
    "        fill_prev = self.__get_param_value('fill_prev', 'n', **kwargs)\n",
    "        \n",
    "        start_adj = start\n",
    "        \n",
    "        if fill_prev == 'y':\n",
    "            start_adj = (datetime.strptime(start, FinancialDataAPI.__date_format) - timedelta(days=10)).strftime(FinancialDataAPI.__date_format)\n",
    "        \n",
    "        df = df[(df['Ticker'].isin(tickers)) & (df['Date'] >= start_adj) & (df['Date'] <= end)].copy()\n",
    "        \n",
    "        if adj == 'y':\n",
    "            df['Adj Factor'] = df['Adj. Close'] - df['Close']\n",
    "            df[field_long_name] = df[field_long_name] + df['Adj Factor']\n",
    "            \n",
    "        df = df[['Ticker', 'Date', field_long_name]]\n",
    "        \n",
    "        df = self.__expand_to_calendar_dates(df, tickers, start_adj, end)\n",
    "        \n",
    "        if fill_prev == 'y':\n",
    "            df = df.fillna(method='ffill')\n",
    "            \n",
    "        df = df[df['Date'] >= start]\n",
    "        \n",
    "        # make sure the ticker order is the same as the request\n",
    "        df['Ticker Order'] = df['Ticker'].apply(lambda x: tickers.index(x))\n",
    "        df = df.sort_values(['Ticker Order', 'Date'])\n",
    "        del df['Ticker Order']\n",
    "        df = df.set_index('Ticker')\n",
    "        \n",
    "        return df.copy()\n",
    "    \n",
    "    \n",
    "    def __get_market_data(self, tickers, field_dict, **kwargs):\n",
    "        \"\"\"\n",
    "            The function retrieves the market data\n",
    "            for a given list of tickers and a field metadata as dictionary (use __get_field).\n",
    "            Only one field is allowed and field must be description data.\n",
    "            \n",
    "            Param:\n",
    "            start -> Date = required\n",
    "            end -> Date = required\n",
    "            fill_prev -> String [y/n]\n",
    "        \"\"\"\n",
    "        \n",
    "        data_set = field_dict['data_set']\n",
    "        field_long_name = field_dict['Long Name']\n",
    "        \n",
    "        df = FinancialDataAPI.__data_dict[data_set]\n",
    "        \n",
    "        start = self.__get_param_value('start', **kwargs)\n",
    "        end = self.__get_param_value('end', **kwargs)\n",
    "        fill_prev = self.__get_param_value('fill_prev', 'n', **kwargs)\n",
    "        \n",
    "        start_adj = start\n",
    "        \n",
    "        if fill_prev == 'y':\n",
    "            start_adj = (datetime.strptime(start, FinancialDataAPI.__date_format) - timedelta(days=10)).strftime(FinancialDataAPI.__date_format)\n",
    "        \n",
    "        df = df[(df['Ticker'].isin(tickers)) & (df['Date'] >= start_adj) & (df['Date'] <= end)].copy()\n",
    "        \n",
    "        df = df[['Ticker', 'Date', field_long_name]]\n",
    "        \n",
    "        df = self.__expand_to_calendar_dates(df, tickers, start_adj, end)\n",
    "        \n",
    "        if fill_prev == 'y':\n",
    "            df = df.fillna(method='ffill')\n",
    "            \n",
    "        df = df[df['Date'] >= start]\n",
    "        \n",
    "        # make sure the ticker order is the same as the request\n",
    "        df['Ticker Order'] = df['Ticker'].apply(lambda x: tickers.index(x))\n",
    "        df = df.sort_values(['Ticker Order', 'Date'])\n",
    "        del df['Ticker Order']\n",
    "        df = df.set_index('Ticker')\n",
    "        \n",
    "        \n",
    "        return df.copy()\n",
    "    \n",
    "    \n",
    "    def __fundamental_get_raw_data(self, data_set_name, tickers, field_long_name, as_of_date):\n",
    "        \"\"\"\n",
    "            The function gets the raw fundamental data for the given ticker, field and as of date\n",
    "        \"\"\"\n",
    "        \n",
    "        df = FinancialDataAPI.__data_dict[data_set_name]\n",
    "        \n",
    "        # free version of the bulk data from SimFin doesn't provide full restated history\n",
    "        # if use the paid version, then use 'Restated Date' otherwise use 'Publish Date'\n",
    "        df = df[(df['Ticker'].isin(tickers)) & (df['Publish Date'] <= as_of_date)].copy()\n",
    "        \n",
    "        df['As of Date'] = as_of_date\n",
    "        df['As of Date'] = df['As of Date'].astype('datetime64')\n",
    "        \n",
    "        cols = df.columns.tolist()\n",
    "        fixed_cols = cols[:cols.index('Restated Date') + 1] + ['As of Date']\n",
    "        raw_data_cols = [c for c in fixed_cols + [field_long_name] if c != 'SimFinId']\n",
    "        \n",
    "        df = df[raw_data_cols].sort_values(['Ticker', 'Publish Date'])\n",
    "        df = df.groupby(['Ticker', 'Report Date']).tail(1).sort_values(['Ticker', 'Report Date'])\n",
    "        \n",
    "        return df.copy()\n",
    "    \n",
    "    \n",
    "    def __fundamental_fill_missing_tickers(self, df, tickers, as_of_date):\n",
    "        \"\"\"\n",
    "            The function check if all tickers in the df index, if no means no data and will fill the ticker with NaN\n",
    "        \"\"\"\n",
    "        \n",
    "        if 'Ticker' in df.columns.tolist():\n",
    "            df = df.set_index('Ticker')\n",
    "        \n",
    "        missing_tickers = [tk for tk in tickers if tk not in df.index.tolist()]\n",
    "        if len(missing_tickers):\n",
    "            for tk in missing_tickers:\n",
    "                df.loc[tk] = np.NaN\n",
    "                df.loc[tk, 'As of Date'] = pd.to_datetime(as_of_date, format=FinancialDataAPI.__date_format)\n",
    "            \n",
    "        return df.reset_index()\n",
    "    \n",
    "    \n",
    "    def __fundamental_offset_period(self, data_set_name, tickers, field_long_name, offset_start, offset_end, as_of_date):\n",
    "        \"\"\"\n",
    "            The function gets the fundamental data for the given offset periods\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.__fundamental_get_raw_data(data_set_name, tickers, field_long_name, as_of_date)\n",
    "        \n",
    "        if offset_start == offset_end:\n",
    "            offset_func = lambda d: d.sort_values(['Ticker', 'Report Date']).iloc[offset_end-1]\n",
    "        else:\n",
    "            if offset_end < 0:\n",
    "                offset_func = lambda d: d.sort_values(['Ticker', 'Report Date']).iloc[offset_start-1:offset_end+1]\n",
    "            else:\n",
    "                offset_func = lambda d: d.sort_values(['Ticker', 'Report Date']).iloc[offset_start-1:]\n",
    "        \n",
    "        df = df.groupby('Ticker').apply(offset_func)\n",
    "        \n",
    "        # add missing tickers\n",
    "        df = self.__fundamental_fill_missing_tickers(df, tickers, as_of_date)\n",
    "        \n",
    "        # make sure the ticker order is the same as the request\n",
    "        df['Ticker Order'] = df['Ticker'].apply(lambda x: tickers.index(x))\n",
    "        df = df.sort_values(['Ticker Order', 'As of Date', 'Report Date'])\n",
    "        del df['Ticker Order']\n",
    "        df = df.set_index('Ticker')\n",
    "        \n",
    "        return df.copy()\n",
    "    \n",
    "    \n",
    "    def __fundamental_offset_period_aod_range(self, data_set_name, tickers, field_long_name, offset_start, offset_end, as_of_date_start, as_of_date_end):\n",
    "        \"\"\"\n",
    "            The function gets the offset period data for a given as of date range.\n",
    "        \"\"\"\n",
    "        df = FinancialDataAPI.__data_dict[data_set_name]\n",
    "        \n",
    "        # free version of the bulk data from SimFin doesn't provide full restated history\n",
    "        # if use the paid version, then use 'Restated Date' otherwise use 'Report Date'\n",
    "        dt_range = df[\n",
    "            (df['Ticker'].isin(tickers)) & \n",
    "            (df['Publish Date'] >= as_of_date_start) & \n",
    "            (df['Publish Date'] <= as_of_date_end)\n",
    "        ]['Publish Date'].unique()\n",
    "        \n",
    "        dt_range = [pd.to_datetime(dt).strftime(FinancialDataAPI.__date_format) for dt in dt_range]\n",
    "        \n",
    "        # make sure we have enough data\n",
    "        if len(dt_range):\n",
    "        \n",
    "            if as_of_date_start != dt_range[0]:\n",
    "                dt_range = [as_of_date_start] + dt_range\n",
    "\n",
    "            full_dt_range = [pd.to_datetime(dt).strftime(FinancialDataAPI.__date_format) for dt in pd.date_range(start=as_of_date_start, end=as_of_date_end)]\n",
    "\n",
    "            df_list = []\n",
    "            last_df = None\n",
    "\n",
    "            for dt in full_dt_range:\n",
    "                if dt in dt_range:\n",
    "                    last_df = self.__fundamental_offset_period(data_set_name, tickers, field_long_name, offset_start, offset_end, dt)\n",
    "                    df_list.append(last_df.copy())\n",
    "                else:\n",
    "                    last_df['As of Date'] = dt\n",
    "                    df_list.append(last_df.copy())\n",
    "\n",
    "            df = pd.concat(df_list, sort=False).reset_index()\n",
    "            df['As of Date'] = pd.to_datetime(df['As of Date'], format=FinancialDataAPI.__date_format)\n",
    "\n",
    "            # make sure the ticker order is the same as the request\n",
    "            df['Ticker Order'] = df['Ticker'].apply(lambda x: tickers.index(x))\n",
    "            df = df.sort_values(['Ticker Order', 'As of Date', 'Publish Date'])\n",
    "            del df['Ticker Order']\n",
    "            df = df.set_index('Ticker')\n",
    "            \n",
    "            return df.copy()\n",
    "        else:\n",
    "            # todo return for all tickers NA\n",
    "            raise Exception('Err: No enough data.')\n",
    "        \n",
    "    \n",
    "    def __fundamental_absolute_period_q_ttm(self, data_set_name, tickers, field_long_name, y_start, q_start, y_end, q_end, as_of_date):\n",
    "        \"\"\"\n",
    "            The function gets the quarterly and last 12 months fundamental data for the given absolute periods\n",
    "        \"\"\"\n",
    "            \n",
    "        df = self.__fundamental_get_raw_data(data_set_name, tickers, field_long_name, as_of_date)\n",
    "        \n",
    "        df['Quarter'] = df['Fiscal Period'].str[-1:].astype(int)\n",
    "        \n",
    "        df = df[\n",
    "            (df['Fiscal Year'] >= y_start) & (df['Fiscal Year'] <= y_end)\n",
    "            & (df['Quarter'] >= q_start) & (df['Quarter'] <= q_end)\n",
    "        ]\n",
    "        \n",
    "        cols = [c for c in df.columns.tolist() if c != 'Quarter']\n",
    "        df = df[cols]\n",
    "        \n",
    "        # add missing tickers\n",
    "        df = self.__fundamental_fill_missing_tickers(df, tickers, as_of_date)\n",
    "        \n",
    "        # make sure the ticker order is the same as the request\n",
    "        df = df.reset_index()\n",
    "        df['Ticker Order'] = df['Ticker'].apply(lambda x: tickers.index(x))\n",
    "        df = df.sort_values(['Ticker Order', 'As of Date', 'Publish Date'])\n",
    "        del df['Ticker Order']\n",
    "        df = df.set_index('Ticker')\n",
    "        del df['index']\n",
    "        \n",
    "        return df.copy()\n",
    "    \n",
    "    \n",
    "    def __fundamental_absolute_period_a(self, data_set_name, tickers, field_long_name, y_start, y_end, as_of_date):\n",
    "        \"\"\"\n",
    "            The function gets the annually fundamental data for the given absolute periods\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.__fundamental_get_raw_data(data_set_name, tickers, field_long_name, as_of_date)\n",
    "        \n",
    "        df = df[\n",
    "            (df['Fiscal Year'] >= y_start) & (df['Fiscal Year'] <= y_end)\n",
    "        ]\n",
    "        \n",
    "        # add missing tickers\n",
    "        df = self.__fundamental_fill_missing_tickers(df, tickers, as_of_date)\n",
    "        \n",
    "        # make sure the ticker order is the same as the request\n",
    "        df = df.reset_index()\n",
    "        df['Ticker Order'] = df['Ticker'].apply(lambda x: tickers.index(x))\n",
    "        df = df.sort_values(['Ticker Order', 'As of Date', 'Publish Date'])\n",
    "        del df['Ticker Order']\n",
    "        df = df.set_index('Ticker')\n",
    "        del df['index']\n",
    "        \n",
    "        return df.copy()\n",
    "    \n",
    "    \n",
    "    def __get_fundamental_data(self, tickers, field_dict, **kwargs):\n",
    "        \"\"\"\n",
    "            The function retrieves the fundamental data\n",
    "            for a given list of tickers and a field metadata as dictionary (use __get_field).\n",
    "            Only one field is allowed and field must be description data.\n",
    "            \n",
    "            Param:\n",
    "            Period Type: pt -> String [q/a/ttm] = ttm\n",
    "            \n",
    "            Offset Start: offset_start -> Int = 0\n",
    "            Offset End: offset_end -> Int = 0\n",
    "            \n",
    "            Year Start: y_start -> Int = latest year\n",
    "            Year End: y_end -> Int = latest year\n",
    "            \n",
    "            Quarter Start: q_start: Int [1/2/3/4] = latest quarter\n",
    "            Quarter End: q_end: Int [1/2/3/4] = latest quarter\n",
    "            \n",
    "            As of Date Start: as_of_date_start -> Date = date.today()\n",
    "            As of Date End: as_of_date_end -> Date = date.today()\n",
    "        \"\"\"\n",
    "        \n",
    "        data_set_list = field_dict['data_set'].split('/')\n",
    "        data_set_dict = {d.split('-')[1]:d for d in data_set_list}\n",
    "        field_long_name = field_dict['Long Name']\n",
    "        \n",
    "        pt = self.__get_param_value('pt', 'ttm', **kwargs)\n",
    "        \n",
    "        y_q_none = -1\n",
    "        \n",
    "        y_start = self.__get_param_value('y_start', y_q_none, **kwargs)\n",
    "        y_end = self.__get_param_value('y_end', y_q_none, **kwargs)\n",
    "        \n",
    "        q_start = self.__get_param_value('q_start', y_q_none, **kwargs)\n",
    "        q_end = self.__get_param_value('q_end', y_q_none, **kwargs)\n",
    "        \n",
    "        offset_start = self.__get_param_value('offset_start', 0, **kwargs)\n",
    "        offset_end = self.__get_param_value('offset_end', 0, **kwargs)\n",
    "        offset = offset_end\n",
    "        \n",
    "        if pt == 'q':\n",
    "            data_set_name = data_set_dict['quarterly']\n",
    "        elif pt == 'a':\n",
    "            data_set_name = data_set_dict['annual']\n",
    "        elif pt == 'ttm':\n",
    "            data_set_name = data_set_dict['ttm']\n",
    "        \n",
    "        as_of_date_start = self.__get_param_value('as_of_date_start', date.today(), **kwargs)\n",
    "        as_of_date_end = self.__get_param_value('as_of_date_end', date.today(), **kwargs)\n",
    "        as_of_date = as_of_date_end # default as of date is the as of date end\n",
    "        \n",
    "        # default is only one as of date and is_as_of_date_range is False\n",
    "        is_as_of_date_range = False\n",
    "        \n",
    "        if as_of_date_start > as_of_date_end:\n",
    "            raise Exception('Err: The start as of date is larger than the end date.')\n",
    "        elif as_of_date_start < as_of_date_end:\n",
    "            # request only in the case of only one offset period is given\n",
    "            is_as_of_date_range = True\n",
    "        \n",
    "        if pt == 'q' or pt == 'ttm':\n",
    "            # if any of start end y and q is provided, require all or raise exception\n",
    "            # if non of start end y and q is provided, go for offset\n",
    "            \n",
    "            if y_start != y_q_none or y_end != y_q_none or q_start != y_q_none or q_end != y_q_none:\n",
    "                if y_start != y_q_none and y_end != y_q_none and q_start != y_q_none and q_end != y_q_none:\n",
    "                    if is_as_of_date_range:\n",
    "                        raise Exception('Err: As of date range can only be used with offset period.')\n",
    "                    else:\n",
    "                        # get data for the given period\n",
    "                        return self.__fundamental_absolute_period_q_ttm(\n",
    "                            data_set_name, tickers, field_long_name, y_start, q_start, y_end, q_end, as_of_date\n",
    "                        )\n",
    "                else:\n",
    "                    raise Exception('Err: Missing start end year or quarter.')\n",
    "        elif pt == 'a':\n",
    "            # if any of start end y is provided, require all or raise exception\n",
    "            # if non of start end y is provided, go for offset\n",
    "            \n",
    "            if y_start != y_q_none or y_end != y_q_none:\n",
    "                if y_start != y_q_none and y_end != y_q_none:\n",
    "                    if is_as_of_date_range:\n",
    "                        raise Exception('Err: As of date range can only be used with offset period.')\n",
    "                    else:\n",
    "                        # get data for the given period\n",
    "                        return self.__fundamental_absolute_period_a(\n",
    "                            data_set_name, tickers, field_long_name, y_start, y_end, as_of_date\n",
    "                        )\n",
    "                else:\n",
    "                    raise Exception('Err: Missing start end year.')\n",
    "                    \n",
    "        # get data for the given offset period\n",
    "        if is_as_of_date_range:\n",
    "            # request as of date range for the given offset period\n",
    "            return self.__fundamental_offset_period_aod_range(\n",
    "                data_set_name, tickers, field_long_name, offset_start, offset_end, as_of_date_start, as_of_date_end\n",
    "            )\n",
    "        else:\n",
    "            return self.__fundamental_offset_period(\n",
    "                data_set_name, tickers, field_long_name, offset_start, offset_end, as_of_date\n",
    "            )\n",
    "        \n",
    "    \n",
    "    def get_data(self, tickers, field, **kwargs):\n",
    "        \"\"\"\n",
    "            The function returns the data as dataframe\n",
    "            for a given list of tickers and a field name.\n",
    "            Only one field is allowed.\n",
    "            If field is not found, the exception will be raised.\n",
    "        \"\"\"\n",
    "        \n",
    "        # make sure the ticker list is unique\n",
    "        tickers = [tk.upper().strip() for tk in list(dict.fromkeys(tickers))]\n",
    "        \n",
    "        field_dict = self.__get_field(field)\n",
    "        \n",
    "        func_dict = {\n",
    "            'get_description_data': self.__get_description_data,\n",
    "            'get_pricing_data': self.__get_pricing_data,\n",
    "            'get_market_data': self.__get_market_data,\n",
    "            'get_fundamental_data': self.__get_fundamental_data,\n",
    "        }\n",
    "        \n",
    "        func = func_dict[field_dict['func']]\n",
    "        \n",
    "        return func(tickers, field_dict, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = FinancialDataAPI()\n",
    "# api.list_data_sets()\n",
    "# api.get_data_set('shareprices-daily').Date\n",
    "# api.get_classification(level='sector')\n",
    "# api.get_ticker_by_classification(['Technology'])\n",
    "# api.get_data(['MSFT', 'IBM'], 'Sector')\n",
    "# api.get_data(['MSFT', 'IBM'], 'Close', Start=date(2010, 12, 31) - timedelta(days=30), End=date(2010, 12, 31), Adj='y')\n",
    "# api.get_data(['MSFT', 'IBM'], 'Dividend', Start=date(2010, 12, 31) - timedelta(days=300), End=date(2010, 12, 31)).dropna()\n",
    "# api.get_data(['MSFT', 'IBM'], 'Net Income', pt='ttm', offset_start=-3, offset_end=0, as_of_date_start=date(2020, 12, 31), as_of_date_end=date(2021, 12, 31))\n",
    "\n",
    "# api.get_data(['MSFT', 'IBM'], 'Net Income', pt='ttm', offset_start=-3, offset_end=0, as_of_date_start=date(2020, 12, 31), as_of_date_end=date(2020, 12, 31))\n",
    "# api.get_data(['MSFT', 'IBM'], 'Net Income', pt='ttm', offset_start=0, offset_end=0, as_of_date_start=date(2019, 12, 31), as_of_date_end=date(2021, 12, 31))\n",
    "# api.get_data(['MSFT', 'IBM'], 'Net Income', pt='q', y_start=2013, y_end=2015, q_start=3, q_end=4, as_of_date_start=date(2020, 12, 31), as_of_date_end=date(2020, 12, 31))\n",
    "# api.get_data(['MSFT', 'IBM'], 'Net Income', pt='a', y_start=2013, y_end=2015, as_of_date_start=date(2020, 12, 31), as_of_date_end=date(2020, 12, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bugfix as of date range for rel period between 2020 to 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_tickers = api.get_ticker_by_classification(\n",
    "    ['Energy'], as_of_date=date(2018, 12, 31)\n",
    ")\n",
    "\n",
    "print(energy_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = api.get_data(['MSFT', 'WFT'], 'Net Income', pt='q', y_start=2013, y_end=2015, q_start=3, q_end=4, as_of_date_start=date(2020, 12, 31), as_of_date_end=date(2020, 12, 31))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.get_data(['MSFT', 'WFT'], 'Net Income', pt='a', y_start=2013, y_end=2015, as_of_date_start=date(2020, 12, 31), as_of_date_end=date(2020, 12, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = date(2018, 12, 31)\n",
    "end = date(2019, 12, 31)\n",
    "\n",
    "df_net_income = api.get_data(\n",
    "    energy_tickers, 'Net Income', pt='ttm', offset_start=0, offset_end=0,\n",
    "    as_of_date_start=start, as_of_date_end=end\n",
    ")\n",
    "\n",
    "df_sh_out = api.get_data(\n",
    "    energy_tickers, 'Shares (Basic)', pt='ttm', offset_start=0, offset_end=0,\n",
    "    as_of_date_start=start, as_of_date_end=end\n",
    ")\n",
    "\n",
    "df_price = api.get_data(energy_tickers, 'Close', start=start, end=end, Adj='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = df_net_income['Net Income'] / df_sh_out['Shares (Basic)']\n",
    "pe = df_price['Close'] / eps\n",
    "df = pd.DataFrame(pe, columns=['PE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sh_out['Shares (Basic)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
